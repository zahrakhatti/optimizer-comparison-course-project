# Deep Learning Optimizer Comparison on FashionMNIST and CIFAR10

This repository contains code and experiments for comparing optimization algorithms on convolutional neural networks using the FashionMNIST and CIFAR10 datasets in PyTorch.

---

## Project Overview

The main objectives of this project are:

1. Implement and train CNN models on FashionMNIST and CIFAR10 datasets.
2. Compare different optimization algorithms:
   - Stochastic Gradient Descent (SGD)
   - SGD with Momentum
   - Adagrad
   - Adam
   - Custom implementations of Adagrad and Adam
3. Observe and analyze:
   - Training loss behavior
   - Gradient norms
4. Tune algorithm hyperparameters using training and validation sets.
5. Evaluate final performance on the test set.
6. Generate plots for comparison and draw conclusions.
